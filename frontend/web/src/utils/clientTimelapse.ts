import type { OverlayConfig } from '../../../packages/shared/types';
import { OverlayRenderer } from './overlayRenderer';

interface ClientTimelapseOptions {
  videoBlob: Blob;
  recordingSeconds: number;
  outputSeconds: number;
  overlayConfig: OverlayConfig | null;
  onProgress: (percent: number) => void;
}

/**
 * í”„ë¡ íŠ¸ì—”ë“œì—ì„œ íƒ€ì„ë©ìŠ¤ ìƒì„± (ì„œë²„ ë¶ˆí•„ìš”)
 * - video.playbackRateë¡œ ë°°ì† ì¬ìƒ
 * - Canvasì— í”„ë ˆì„ + ì˜¤ë²„ë ˆì´ ê·¸ë¦¬ê¸°
 * - MediaRecorderë¡œ ìµœì¢… ì˜ìƒ ìº¡ì²˜
 */
export async function createClientTimelapse({
  videoBlob,
  recordingSeconds,
  outputSeconds,
  overlayConfig,
  onProgress,
}: ClientTimelapseOptions): Promise<Blob> {
  return new Promise((resolve, reject) => {
    const video = document.createElement('video');
    video.muted = true;
    video.playsInline = true;
    video.src = URL.createObjectURL(videoBlob);

    video.onloadeddata = async () => {
      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      const ctx = canvas.getContext('2d')!;

      // ë°°ì† ê³„ì‚°
      const speed = video.duration / outputSeconds;
      // ë¸Œë¼ìš°ì € playbackRate ìµœëŒ€ 16x, ê·¸ ì´ìƒì€ í”„ë ˆì„ ìŠ¤í‚µìœ¼ë¡œ
      const playbackRate = Math.min(speed, 16);

      console.log(`ğŸ¬ í´ë¼ì´ì–¸íŠ¸ íƒ€ì„ë©ìŠ¤: ${video.duration.toFixed(1)}ì´ˆ â†’ ${outputSeconds}ì´ˆ (${speed.toFixed(1)}x, playbackRate=${playbackRate}x)`);

      // ì˜¤ë²„ë ˆì´ ë Œë”ëŸ¬
      let renderer: OverlayRenderer | null = null;
      const hasOverlay = overlayConfig && overlayConfig.theme !== 'none';
      if (hasOverlay && overlayConfig) {
        renderer = new OverlayRenderer(overlayConfig, recordingSeconds, outputSeconds);
        renderer.setVideoDuration(video.duration);
      }

      // MediaRecorder ì„¤ì •
      const stream = canvas.captureStream(30);
      const chunks: Blob[] = [];

      const mimeType = MediaRecorder.isTypeSupported('video/mp4;codecs=avc1')
        ? 'video/mp4;codecs=avc1'
        : 'video/webm;codecs=vp8';

      const recorder = new MediaRecorder(stream, {
        mimeType,
        videoBitsPerSecond: 4_000_000,
      });

      recorder.ondataavailable = (e) => {
        if (e.data.size > 0) chunks.push(e.data);
      };

      recorder.onstop = () => {
        const blob = new Blob(chunks, { type: mimeType });
        URL.revokeObjectURL(video.src);
        resolve(blob);
      };

      recorder.onerror = () => {
        URL.revokeObjectURL(video.src);
        reject(new Error('íƒ€ì„ë©ìŠ¤ ìƒì„± ì‹¤íŒ¨'));
      };

      // ë°°ì†ì´ 16x ì´ˆê³¼ë©´ í”„ë ˆì„ ìŠ¤í‚µ ë°©ì‹
      if (speed > 16) {
        recorder.start(100);
        await renderByFrameSkip(video, canvas, ctx, renderer, speed, outputSeconds, onProgress);
        setTimeout(() => recorder.stop(), 200);
      } else {
        // playbackRate ë°©ì‹ (ë¶€ë“œëŸ¬ì›€)
        video.playbackRate = playbackRate;
        recorder.start(100);

        const captureFrame = () => {
          if (video.ended || video.paused) {
            onProgress(100);
            setTimeout(() => recorder.stop(), 200);
            return;
          }

          ctx.drawImage(video, 0, 0);
          if (renderer) {
            renderer.render(ctx, canvas.width, canvas.height, video.currentTime);
          }

          const progress = Math.round((video.currentTime / video.duration) * 100);
          onProgress(progress);

          requestAnimationFrame(captureFrame);
        };

        video.onended = () => {
          onProgress(100);
          setTimeout(() => recorder.stop(), 200);
        };

        await video.play();
        captureFrame();
      }
    };

    video.onerror = () => reject(new Error('ì˜ìƒ ë¡œë“œ ì‹¤íŒ¨'));
  });
}

/**
 * í”„ë ˆì„ ìŠ¤í‚µ ë°©ì‹ (16x ì´ˆê³¼ ë°°ì†ìš©)
 * ì¼ì • ê°„ê²©ìœ¼ë¡œ ì‹œí¬ â†’ ìº¡ì²˜ ë°˜ë³µ
 */
async function renderByFrameSkip(
  video: HTMLVideoElement,
  canvas: HTMLCanvasElement,
  ctx: CanvasRenderingContext2D,
  renderer: OverlayRenderer | null,
  speed: number,
  outputSeconds: number,
  onProgress: (percent: number) => void,
) {
  const fps = 30;
  const totalFrames = outputSeconds * fps;
  const timeStep = video.duration / totalFrames;
  void speed; // used for logging only

  for (let i = 0; i < totalFrames; i++) {
    const seekTime = i * timeStep;

    // ì‹œí¬ í›„ í”„ë ˆì„ ìº¡ì²˜
    await new Promise<void>((resolve) => {
      video.currentTime = seekTime;
      video.onseeked = () => {
        ctx.drawImage(video, 0, 0);
        if (renderer) {
          renderer.render(ctx, canvas.width, canvas.height, video.currentTime);
        }
        resolve();
      };
    });

    // 30fps íƒ€ì´ë° ìœ ì§€ (Canvas captureStreamì´ í”„ë ˆì„ ìº¡ì²˜í•˜ë„ë¡)
    await new Promise((r) => setTimeout(r, 1000 / fps));

    if (i % 10 === 0) {
      onProgress(Math.round((i / totalFrames) * 100));
    }
  }
}
